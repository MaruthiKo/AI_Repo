{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3LS8gSef-BD",
        "outputId": "42152200-9b80-4149-f5d6-9a4a1ca808a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.10/dist-packages (0.9.25.post1)\n",
            "Requirement already satisfied: deeplake in /usr/local/lib/python3.10/dist-packages (3.8.13)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: llama_hub in /usr/local/lib/python3.10/dist-packages (0.0.65)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.29.0)\n",
            "Requirement already satisfied: replicate in /usr/local/lib/python3.10/dist-packages (0.22.0)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from llama-index) (4.12.2)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.6.3)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.2.14)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2023.6.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.26.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.5.8)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.23.5)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.5.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (4.9.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.9.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from deeplake) (9.4.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from deeplake) (1.33.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from deeplake) (8.1.7)\n",
            "Requirement already satisfied: pathos in /usr/local/lib/python3.10/dist-packages (from deeplake) (0.3.1)\n",
            "Requirement already satisfied: humbug>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from deeplake) (0.3.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deeplake) (4.66.1)\n",
            "Requirement already satisfied: lz4 in /usr/local/lib/python3.10/dist-packages (from deeplake) (4.3.3)\n",
            "Requirement already satisfied: pyjwt in /usr/lib/python3/dist-packages (from deeplake) (2.3.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from deeplake) (2.5.3)\n",
            "Requirement already satisfied: libdeeplake==0.0.92 in /usr/local/lib/python3.10/dist-packages (from deeplake) (0.0.92)\n",
            "Requirement already satisfied: aioboto3>=10.4.0 in /usr/local/lib/python3.10/dist-packages (from deeplake) (12.1.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from libdeeplake==0.0.92->deeplake) (0.3.7)\n",
            "Requirement already satisfied: html2text in /usr/local/lib/python3.10/dist-packages (from llama_hub) (2020.1.16)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from llama_hub) (5.9.5)\n",
            "Requirement already satisfied: pyaml<24.0.0,>=23.9.7 in /usr/local/lib/python3.10/dist-packages (from llama_hub) (23.12.0)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.10/dist-packages (from llama_hub) (1.3.4)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.2)\n",
            "Requirement already satisfied: importlib-metadata<7,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.11.0)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.2)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (10.0.1)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.8.2)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.2)\n",
            "Requirement already satisfied: validators<1,>=0.2 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.22.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.40)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.8.1b0)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.2)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.0.0)\n",
            "Requirement already satisfied: aiobotocore[boto3]==2.8.0 in /usr/local/lib/python3.10/dist-packages (from aioboto3>=10.4.0->deeplake) (2.8.0)\n",
            "Requirement already satisfied: botocore<1.33.2,>=1.32.4 in /usr/local/lib/python3.10/dist-packages (from aiobotocore[boto3]==2.8.0->aioboto3>=10.4.0->deeplake) (1.33.1)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /usr/local/lib/python3.10/dist-packages (from aiobotocore[boto3]==2.8.0->aioboto3>=10.4.0->deeplake) (1.14.1)\n",
            "Requirement already satisfied: aioitertools<1.0.0,>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from aiobotocore[boto3]==2.8.0->aioboto3>=10.4.0->deeplake) (0.11.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (4.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.2->llama-index) (2.5)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->deeplake) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from boto3->deeplake) (0.8.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index) (1.0.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index) (1.3.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index) (0.14.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=1.4->streamlit) (3.17.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (2023.6.3)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index) (1.7.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index) (2023.3.post1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml<24.0.0,>=23.9.7->llama_hub) (6.0.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->deeplake) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.6 in /usr/local/lib/python3.10/dist-packages (from pydantic->deeplake) (2.14.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index) (2.0.7)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index) (3.0.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index) (3.20.1)\n",
            "Requirement already satisfied: ppft>=1.7.6.7 in /usr/local/lib/python3.10/dist-packages (from pathos->deeplake) (1.7.6.7)\n",
            "Requirement already satisfied: pox>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from pathos->deeplake) (0.3.3)\n",
            "Requirement already satisfied: multiprocess>=0.70.15 in /usr/local/lib/python3.10/dist-packages (from pathos->deeplake) (0.70.15)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index) (1.2.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.32.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.15.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index deeplake python-dotenv llama_hub streamlit deeplake replicate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import textwrap\n",
        "from dotenv import load_dotenv\n",
        "from llama_index import download_loader\n",
        "from llama_hub.github_repo import GithubRepositoryReader, GithubClient\n",
        "from llama_index import VectorStoreIndex\n",
        "from llama_index.vector_stores import DeepLakeVectorStore\n",
        "from llama_index.storage.storage_context import StorageContext\n",
        "from llama_index.retrievers import VectorIndexRetriever\n",
        "from llama_index import get_response_synthesizer\n",
        "from llama_index.indices.postprocessor import SimilarityPostprocessor\n",
        "from llama_index.query_engine import RetrieverQueryEngine\n",
        "from llama_index.llms import Replicate\n",
        "from llama_index import ServiceContext\n",
        "import deeplake\n",
        "import re"
      ],
      "metadata": {
        "id": "lMqY-bPIgPep"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv()\n",
        "\n",
        "replicate_token = os.getenv(\"REPLICATE_API_TOKEN\")\n",
        "active_loop_token = os.getenv(\"ACTIVELOOP_TOKEN\")\n",
        "dataset_path = os.getenv(\"DATASET_PATH\")\n",
        "github_token = os.getenv(\"GITHUB_TOKEN\")"
      ],
      "metadata": {
        "id": "oHNZ6rhShaLQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_github_url(url):\n",
        "    pattern = r\"https://github\\.com/([^/]+)/([^/]+)\"\n",
        "    match = re.match(pattern, url)\n",
        "    return match.groups() if match else (None, None)"
      ],
      "metadata": {
        "id": "4aBeapwGheR2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_owner_repo(owner, repo):\n",
        "    return bool(owner) and bool(repo)\n",
        "\n",
        "def initialize_github_client():\n",
        "    github_token = os.getenv(\"GITHUB_TOKEN\")\n",
        "    return GithubClient(github_token)"
      ],
      "metadata": {
        "id": "BuW0M1Y2hglr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(message, chat_history):\n",
        "    if not replicate_token:\n",
        "        raise EnvironmentError(\"Replicate token not found in environment variables\")\n",
        "\n",
        "    # Check for GitHub Token\n",
        "    if not github_token:\n",
        "        raise EnvironmentError(\"GitHub token not found in environment variables\")\n",
        "\n",
        "    # Check for Activeloop Token\n",
        "    if not active_loop_token:\n",
        "        raise EnvironmentError(\"Activeloop token not found in environment variables\")\n",
        "\n",
        "    github_client = initialize_github_client()\n",
        "    download_loader(\"GithubRepositoryReader\")\n",
        "\n",
        "    github_url = \"https://github.com/facebookresearch/segment-anything\"\n",
        "    # owner, repo = parse_github_url(github_url)\n",
        "\n",
        "    while True:\n",
        "        owner, repo = parse_github_url(github_url)\n",
        "        if validate_owner_repo(owner, repo):\n",
        "            loader = GithubRepositoryReader(\n",
        "                github_client,\n",
        "                owner = owner,\n",
        "                repo = repo,\n",
        "                filter_file_extensions=(\n",
        "                    [\".py\", \".js\", \".ts\", \".md\"],\n",
        "                    GithubRepositoryReader.FilterType.INCLUDE,\n",
        "                ),\n",
        "                verbose=False,\n",
        "                concurrent_requests=5,\n",
        "            )\n",
        "            print(f\"Loading {repo} repository by {owner}\")\n",
        "            docs = loader.load_data(branch=\"main\")\n",
        "            print(\"Documents uploaded: \")\n",
        "            for doc in docs:\n",
        "                print(doc.metadata)\n",
        "            break # Exit the loop once the valid URL is processed\n",
        "        else:\n",
        "            print(\"Invalid GitHub URL. Please try again.\")\n",
        "\n",
        "    print(\"Uploading to vector store... \")\n",
        "\n",
        "    # Create vector store and upload data\n",
        "    try:\n",
        "        exists = deeplake.exists(dataset_path)\n",
        "        if exists:\n",
        "            vector_store = DeepLakeVectorStore(\n",
        "                dataset_path=dataset_path,\n",
        "                overwrite=False,\n",
        "                runtime={\"tensor_db\": True},\n",
        "            )\n",
        "        else:\n",
        "            vector_store = DeepLakeVectorStore(\n",
        "                dataset_path=dataset_path,\n",
        "                overwrite=True,\n",
        "                runtime={\"tensor_db\": True},\n",
        "            )\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred while creating or fetching the vector store: {str(e)}\")\n",
        "\n",
        "    llm = Replicate(model=\"mistralai/mistral-7b-instruct-v0.1:5fe0a3d7ac2852264a25279d1dfb798acbc4d49711d126646594e212cb821749\")\n",
        "    service_context = ServiceContext.from_defaults(llm=llm)\n",
        "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "    index = VectorStoreIndex.from_documents(docs, storage_context=storage_context, service_context=service_context)\n",
        "    retriever = VectorIndexRetriever(index=index, similarity_top_k=4)\n",
        "    response_synthesizer = get_response_synthesizer()\n",
        "    query_engine = RetrieverQueryEngine.from_args(\n",
        "        retriever=retriever,\n",
        "        response_mode='default',\n",
        "        response_synthesizer=response_synthesizer,\n",
        "        node_postprocessors=[\n",
        "            SimilarityPostprocessor(similarity_cutoff=0.7)]\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    user_question = message\n",
        "    answer = query_engine.query(user_question)\n",
        "    return str(answer)"
      ],
      "metadata": {
        "id": "g0H-JC-khi1N"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "lyAdv-vFjNUx"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo = gr.ChatInterface(main).queue()"
      ],
      "metadata": {
        "id": "-m6svqkfhoED"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WqjoYC2l4XN6",
        "outputId": "d325d4f3-3094-4cdf-f25a-d668438e777d"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://51e701a9571ebcd221.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://51e701a9571ebcd221.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading segment-anything repository by facebookresearch\n",
            "Documents uploaded: \n",
            "{'file_path': 'CODE_OF_CONDUCT.md', 'file_name': 'CODE_OF_CONDUCT.md', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/CODE_OF_CONDUCT.md'}\n",
            "{'file_path': 'CONTRIBUTING.md', 'file_name': 'CONTRIBUTING.md', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/CONTRIBUTING.md'}\n",
            "{'file_path': 'README.md', 'file_name': 'README.md', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/README.md'}\n",
            "{'file_path': 'demo/README.md', 'file_name': 'README.md', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/demo/README.md'}\n",
            "{'file_path': 'demo/configs/webpack/common.js', 'file_name': 'common.js', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/demo/configs/webpack/common.js'}\n",
            "{'file_path': 'demo/configs/webpack/dev.js', 'file_name': 'dev.js', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/demo/configs/webpack/dev.js'}\n",
            "{'file_path': 'demo/configs/webpack/prod.js', 'file_name': 'prod.js', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/demo/configs/webpack/prod.js'}\n",
            "{'file_path': 'demo/postcss.config.js', 'file_name': 'postcss.config.js', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/demo/postcss.config.js'}\n",
            "{'file_path': 'demo/tailwind.config.js', 'file_name': 'tailwind.config.js', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/demo/tailwind.config.js'}\n",
            "{'file_path': 'scripts/amg.py', 'file_name': 'amg.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/scripts/amg.py'}\n",
            "{'file_path': 'scripts/export_onnx_model.py', 'file_name': 'export_onnx_model.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/scripts/export_onnx_model.py'}\n",
            "{'file_path': 'segment_anything/__init__.py', 'file_name': '__init__.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/segment_anything/__init__.py'}\n",
            "{'file_path': 'segment_anything/automatic_mask_generator.py', 'file_name': 'automatic_mask_generator.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/segment_anything/automatic_mask_generator.py'}\n",
            "{'file_path': 'segment_anything/build_sam.py', 'file_name': 'build_sam.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/segment_anything/build_sam.py'}\n",
            "{'file_path': 'segment_anything/modeling/__init__.py', 'file_name': '__init__.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/segment_anything/modeling/__init__.py'}\n",
            "{'file_path': 'segment_anything/modeling/common.py', 'file_name': 'common.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/segment_anything/modeling/common.py'}\n",
            "{'file_path': 'segment_anything/modeling/image_encoder.py', 'file_name': 'image_encoder.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/segment_anything/modeling/image_encoder.py'}\n",
            "{'file_path': 'segment_anything/modeling/mask_decoder.py', 'file_name': 'mask_decoder.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/segment_anything/modeling/mask_decoder.py'}\n",
            "{'file_path': 'segment_anything/modeling/prompt_encoder.py', 'file_name': 'prompt_encoder.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/segment_anything/modeling/prompt_encoder.py'}\n",
            "{'file_path': 'segment_anything/modeling/sam.py', 'file_name': 'sam.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/segment_anything/modeling/sam.py'}\n",
            "{'file_path': 'segment_anything/modeling/transformer.py', 'file_name': 'transformer.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/segment_anything/modeling/transformer.py'}\n",
            "{'file_path': 'segment_anything/predictor.py', 'file_name': 'predictor.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/segment_anything/predictor.py'}\n",
            "{'file_path': 'segment_anything/utils/__init__.py', 'file_name': '__init__.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/segment_anything/utils/__init__.py'}\n",
            "{'file_path': 'segment_anything/utils/amg.py', 'file_name': 'amg.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/segment_anything/utils/amg.py'}\n",
            "{'file_path': 'segment_anything/utils/onnx.py', 'file_name': 'onnx.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/segment_anything/utils/onnx.py'}\n",
            "{'file_path': 'segment_anything/utils/transforms.py', 'file_name': 'transforms.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/segment_anything/utils/transforms.py'}\n",
            "{'file_path': 'setup.py', 'file_name': 'setup.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/setup.py'}\n",
            "Uploading to vector store... \n",
            "Deep Lake Dataset in hub://gamingambidextrous/repochat already exists, loading from the storage\n",
            "Uploading data to deeplake dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 52/52 [00:01<00:00, 38.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset(path='hub://gamingambidextrous/repochat', tensors=['embedding', 'id', 'metadata', 'text'])\n",
            "\n",
            "  tensor      htype       shape      dtype  compression\n",
            "  -------    -------     -------    -------  ------- \n",
            " embedding  embedding  (624, 1536)  float32   None   \n",
            "    id        text      (624, 1)      str     None   \n",
            " metadata     json      (624, 1)      str     None   \n",
            "   text       text      (624, 1)      str     None   \n",
            "Loading segment-anything repository by facebookresearch\n",
            "Documents uploaded: \n",
            "{'file_path': 'CODE_OF_CONDUCT.md', 'file_name': 'CODE_OF_CONDUCT.md', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/CODE_OF_CONDUCT.md'}\n",
            "{'file_path': 'CONTRIBUTING.md', 'file_name': 'CONTRIBUTING.md', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/CONTRIBUTING.md'}\n",
            "{'file_path': 'README.md', 'file_name': 'README.md', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/README.md'}\n",
            "{'file_path': 'demo/README.md', 'file_name': 'README.md', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/demo/README.md'}\n",
            "{'file_path': 'demo/configs/webpack/common.js', 'file_name': 'common.js', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/demo/configs/webpack/common.js'}\n",
            "{'file_path': 'demo/configs/webpack/dev.js', 'file_name': 'dev.js', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/demo/configs/webpack/dev.js'}\n",
            "{'file_path': 'demo/configs/webpack/prod.js', 'file_name': 'prod.js', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/demo/configs/webpack/prod.js'}\n",
            "{'file_path': 'demo/postcss.config.js', 'file_name': 'postcss.config.js', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/demo/postcss.config.js'}\n",
            "{'file_path': 'demo/tailwind.config.js', 'file_name': 'tailwind.config.js', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/demo/tailwind.config.js'}\n",
            "{'file_path': 'scripts/amg.py', 'file_name': 'amg.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/scripts/amg.py'}\n",
            "{'file_path': 'scripts/export_onnx_model.py', 'file_name': 'export_onnx_model.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/scripts/export_onnx_model.py'}\n",
            "{'file_path': 'segment_anything/__init__.py', 'file_name': '__init__.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/segment_anything/__init__.py'}\n",
            "{'file_path': 'segment_anything/automatic_mask_generator.py', 'file_name': 'automatic_mask_generator.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/segment_anything/automatic_mask_generator.py'}\n",
            "{'file_path': 'segment_anything/build_sam.py', 'file_name': 'build_sam.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/segment_anything/build_sam.py'}\n",
            "{'file_path': 'segment_anything/modeling/__init__.py', 'file_name': '__init__.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/segment_anything/modeling/__init__.py'}\n",
            "{'file_path': 'segment_anything/modeling/common.py', 'file_name': 'common.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/segment_anything/modeling/common.py'}\n",
            "{'file_path': 'segment_anything/modeling/image_encoder.py', 'file_name': 'image_encoder.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/segment_anything/modeling/image_encoder.py'}\n",
            "{'file_path': 'segment_anything/modeling/mask_decoder.py', 'file_name': 'mask_decoder.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/segment_anything/modeling/mask_decoder.py'}\n",
            "{'file_path': 'segment_anything/modeling/prompt_encoder.py', 'file_name': 'prompt_encoder.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/segment_anything/modeling/prompt_encoder.py'}\n",
            "{'file_path': 'segment_anything/modeling/sam.py', 'file_name': 'sam.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/segment_anything/modeling/sam.py'}\n",
            "{'file_path': 'segment_anything/modeling/transformer.py', 'file_name': 'transformer.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/segment_anything/modeling/transformer.py'}\n",
            "{'file_path': 'segment_anything/predictor.py', 'file_name': 'predictor.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/segment_anything/predictor.py'}\n",
            "{'file_path': 'segment_anything/utils/__init__.py', 'file_name': '__init__.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/segment_anything/utils/__init__.py'}\n",
            "{'file_path': 'segment_anything/utils/amg.py', 'file_name': 'amg.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/segment_anything/utils/amg.py'}\n",
            "{'file_path': 'segment_anything/utils/onnx.py', 'file_name': 'onnx.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/segment_anything/utils/onnx.py'}\n",
            "{'file_path': 'segment_anything/utils/transforms.py', 'file_name': 'transforms.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/segment_anything/utils/transforms.py'}\n",
            "{'file_path': 'setup.py', 'file_name': 'setup.py', 'url': 'https://github.com/facebookresearch/segment-anything/blob/main/setup.py'}\n",
            "Uploading to vector store... \n",
            "Deep Lake Dataset in hub://gamingambidextrous/repochat already exists, loading from the storage\n",
            "Uploading data to deeplake dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 52/52 [00:01<00:00, 33.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset(path='hub://gamingambidextrous/repochat', tensors=['embedding', 'id', 'metadata', 'text'])\n",
            "\n",
            "  tensor      htype       shape      dtype  compression\n",
            "  -------    -------     -------    -------  ------- \n",
            " embedding  embedding  (676, 1536)  float32   None   \n",
            "    id        text      (676, 1)      str     None   \n",
            " metadata     json      (676, 1)      str     None   \n",
            "   text       text      (676, 1)      str     None   \n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7861 <> https://51e701a9571ebcd221.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gradio deploy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTAsJK-p6K20",
        "outputId": "3f963c2a-9877-4618-d24f-19942a20fd98"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Spaces Repo in '/content'. Collecting metadata, press Enter to accept default value.\n",
            "Enter Spaces app title [content]: Chat with Repo\n",
            "Formatted to Chat_with_Repo. \n",
            "Enter Gradio app file : Assignment.ipynb\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/gradio\", line 8, in <module>\n",
            "    sys.exit(cli())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/cli.py\", line 15, in cli\n",
            "    gradio.deploy_space.deploy()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/deploy_space.py\", line 155, in deploy\n",
            "    configuration = add_configuration_to_readme(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/deploy_space.py\", line 49, in add_configuration_to_readme\n",
            "    raise FileNotFoundError(\"Failed to find Gradio app file.\")\n",
            "FileNotFoundError: Failed to find Gradio app file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "snEbedbO999e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}